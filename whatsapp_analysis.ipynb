{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing text message data - Off Platform Project using Open Ended Guidance from Codecademy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Import and look over your dataset\n",
    "Open your file and export its contents.\n",
    "\n",
    "Take a look at the file. Take note of how the information is organised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Plan your analysis\n",
    "What insights would you like to learn and share from this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load libraries & create instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impport required libraries/install them first in your terminal using pip, \n",
    "# eg pip install pandas. if you are getting errors, such as\n",
    "# AttributeError: module 'inspect' has no attribute 'formatargspec', \n",
    "# try upgrading your libraries eg using\n",
    "# pip install --upgrade pandas matplotlib nltk spacy textblob gensim transformers tqdm\n",
    "# if this fails, try downgrading your Python environment or create a virtual environment\n",
    "# with a downgraded version of Python installed\n",
    "\n",
    "# general purpose/miscellaneous libraries\n",
    "from urllib import request # to open urls  \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "from matplotlib import transforms\n",
    "from transformers import pipeline\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "\n",
    "# nltk libraries \n",
    "import nltk\n",
    "from nltk import pos_tag, RegexpParser # to help mark up words for what part of speech they are in context \n",
    "from nltk.corpus import stopwords, wordnet # to get rid of filler words\n",
    "from nltk.stem import WordNetLemmatizer # to reduce words to their root forms \n",
    "from nltk.tokenize import word_tokenize # to divide text into little bits \n",
    "from nltk.tree import Tree\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# gensim libraries for natural language models \n",
    "import gensim\n",
    "from gensim import corpora, models, similarities, downloader\n",
    "from collections import defaultdict\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import LdaModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "# scikit learn libraries (machine learning)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "\n",
    "# required instances\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "stopwords = set(stopwords.words('english')) # use another language if needed \n",
    "vectoriser = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Read in raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the WhatsApp conversation you would like to analyse, go to the conversation in question on your phone and select Export chat. \n",
    "Save the .txt file to your machine, unzip the file and read it in as a local file. \n",
    "You can read it as both a text file and a dataframe but for common preprocessing libraries to work, the data needs to be a string or bytes like object for now: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please substitute with your own path\n",
    "base_path = r\"C:\\Users\\laura\\OneDrive\\Desktop\\projects\\analyse_your_own_whatsapp\"\n",
    "filename = \"_chat.txt\"\n",
    "path_to_file = os.path.join(base_path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create string object from .txt file, use encoding: \n",
    "with open(path_to_file, 'r', encoding='utf-8') as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Start preprocessing \n",
    "Conduct text preprocessing. \n",
    "Make sure to clean your data and prepare it for analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Choose an NLP model or technique\n",
    "Determine the particular natural language processing models and techniques you will use to conduct your planned analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Conduct your analysis\n",
    "Having planned which analyses you wish to conduct on your data, analyse the data to gain the insight of your choosing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8. Project Extensions \n",
    "Is there a way for you to stretch your skills further? Can you deploy or visualise your work? \n",
    "## Step 9. Communicate your findings. \n",
    "Is there a platform on which you would like to share your findings? Can you create a presentation of your findings? \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
